<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description" content="">
    <meta name="keywords" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="google-site-verification" content="YyDLtcGtegAATTYnhSXnvL6klnX3Bk00jCY9dZQxCTo" />
    <title>Bongard in Wonderland</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/aiml_logo.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="./static/js/index.js"></script>
    <script src="./static/js/fireworks.js"></script>

</head>

<body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <a class="navbar-item" href="https://ml-research.github.io">
                    <span class="icon">
                        <i class="fas fa-home"></i>
                    </span>
                </a>

                <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link">
                        More Research
                    </a>
                    <div class="navbar-dropdown">
                        <a class="navbar-item" href="https://ml-research.github.io/pix2code/">
                            Pix2Code
                        </a>
                        <a class="navbar-item" href="https://ml-research.github.io/NeuralConceptBinder/">
                            Neural Concept Binder
                        </a>
                    </div>
                </div>
            </div>

        </div>
    </nav>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Bongard in Wonderland: Visual Puzzles that Still Make
                            AI Go Mad?
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://ml-research.github.io/people/awuest/index.html" target="_blank">Antonia
                                    W&uuml;st</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.ml.informatik.tu-darmstadt.de/people/ttobiasch/index.html"
                                    target="_blank">Tim
                                    Woydt</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.ml.informatik.tu-darmstadt.de/people/lhelff/index.html"
                                    target="_blank">Lukas Helff</a><sup>1,2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.pip.tu-darmstadt.de/members_pip/inga_ibs.de.jsp"
                                    target="_blank">Inga
                                    Ibs</a><sup>3,4</sup>,</span>
                            <span class="author-block">
                                <a href="https://wolfstam.github.io/" target="_blank">Wolfgang
                                    Stammer</a><sup>1,2</sup>,</span>
                            <span class="author-block">
                                <a href="https://sites.google.com/view/devendradhami" target="_blank">Devendra S.
                                    Dhami</a><sup>5</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.pip.tu-darmstadt.de/members_pip/publications.de.jsp"
                                    target="_blank">Constantin A. Rothkopf
                                </a><sup>2,3,4</sup>,</span>
                            <span class="author-block">
                                <a href="https://ml-research.github.io/people/kkersting/" target="_blank">Kristian
                                    Kersting</a><sup>1,2,4,6</sup>,
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>AI/ML Lab at TU Darmstadt,</span>
                            <span class="author-block"><sup>2</sup>Hessian Center for AI (hessian.AI),</span>
                            <span class="author-block"><sup>3</sup>Institute of Psychology at TU Darmstadt,</span>
                            <span class="author-block"><sup>4</sup>Centre for Cognitive Science at TU Darmstadt,</span>
                            <span class="author-block"><sup>5</sup>Uncertainty in AI Group at TU Eindhoven,</span>
                            <span class="author-block"><sup>6</sup>German Research Center for AI (DFKI)</span>
                            <br />
                            <!-- <span class="author-block"><sup>*</sup>Equal contribution</span> -->
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2410.19546"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2410.19546"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/ml-research/bongard-in-wonderland"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="content has-text-centered">
                    <img src="./static/images/alice_bongard_gen_bw.png" class="motivation-image" alt="Bongard Image" />

                    <h3 class="subtitle has-text-centered">
                        Our paper evaluates the visual reasoning abilities of modern Vision-Language Models (VLMs), like
                        OpenAI's o1, using Bongard problems, classic tests of abstract pattern recognition.
                    </h3>
                </div>
            </div>
        </div>
    </section>




    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <!-- Abstract. -->
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Abstract</h2>
                        <div class="content has-text-justified">
                            <p>
                                Recently, newly developed Vision-Language Models (VLMs), such as OpenAI's o1, have
                                emerged, seemingly demonstrating advanced reasoning capabilities across text and image
                                modalities. However, the depth of these advances in language-guided perception and
                                abstract reasoning remains underexplored, and it is unclear whether these models can
                                truly live up to their ambitious promises. To assess the progress and identify
                                shortcomings, we enter the wonderland of Bongard problems, a set of classic visual
                                reasoning puzzles that require human-like abilities of pattern recognition and abstract
                                reasoning. With our extensive evaluation setup, we show that while VLMs occasionally
                                succeed in identifying discriminative concepts and solving some of the problems, they
                                frequently falter. Surprisingly, even elementary concepts that may seem trivial to
                                humans, such as simple spirals, pose significant challenges. Moreover, when explicitly
                                asked to recognize ground truth concepts, they continue to falter, suggesting not only a
                                lack of understanding of these elementary visual concepts but also an inability to
                                generalize to unseen concepts. We compare the results of VLMs to human performance and
                                observe that a significant gap remains between human visual reasoning capabilities and
                                machine cognition.
                            </p>
                        </div>
                    </div>
                </div>
                <!--/ Abstract. -->

            </div>
        </div>
    </section>


    <section class="section">

        <div class="container is-max-desktop">

            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">VLMs struggle to solve the Bongard Problems</h2>

                    <p>
                        Our experiments indicate that VLMs are still far from mastering Bongard problems.
                        The best-performing model in our paper, o1, solved only 43 out of 100 problems.
                        We also tested the newer model, o3, which did slightly better with 53 solved. However, nearly
                        half the problems remain unsolved.
                    </p>


                    <div class="content has-text-justified">
                        <p>
                        </p>
                        <div class="hero-body">
                            <img src="./static/images/task1.png" class="interpretability-image"
                                alt="Results of VLMs on Bongard Problems" />
                        </div>
                    </div>
                </div>
            </div>
            <br />


            <!-- Vs Humans. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Comparison to Humans</h2>

                    <p>
                        In our experiments, we also compared the performance of VLMs to human participants.
                        We observe that the best human performance surpasses VLM performance by far. Interestingly, when
                        looking at the number of BPs that have been solved at least once by any human or model, the
                        humans were able to solve 95 of the 100 problems.

                    <div class="content has-text-justified">
                        <p>
                        </p>
                        <div class="hero-body">

                            <img src="./static/images/comparison_to_humans.png" class="interpretability-image"
                                alt="Comparison of VLM performance to human performance" />
                        </div>
                    </div>

                </div>
            </div>
            <br />
            <!-- / Interpretability-->
    </section>


    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <!-- Task 2. -->
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <h2 class="title is-3">Can VLMs detect concepts of the Bongard Problems?</h2>
                        <div class="content has-text-justified">

                            <p>
                                We observed that the investigated VLMs
                                performed poorly on the BP dataset. This could be due to
                                difficulties in accurately perceiving the diagrams, as well as
                                reasoning failures, such as incorrectly formulating rules that
                                apply differently to each side. To investigate this in more
                                detail, we designed a follow-up task where we asked the
                                VLMs to detect the concepts of the Bongard Problems. The
                                results show that the VLMs struggle to detect even the most
                                basic concepts, such as simple spirals, which are trivial for
                                humans.
                            </p>

                            <img src="./static/images/task2.png" class="interpretability-image"
                                alt="Detect Concepts 1" />
                            <br />
                            <br />
                            <p>
                                Looking at the intersection of both tasks, we find that the intersection is surprisingly
                                small. Intuitively, one might expect that if a model can solve a BP
                                in the first place (Task 1), it should also be able to detect the concepts (Task 2) for
                                this BP.This large discrepancy highlights a surprising gap between recognizing correct
                                classifications and
                                effectively applying that knowledge in problem-solving.
                            </p>
                            <br />
                            <img src="./static/images/task1_2.png" class="interpretability-image"
                                alt="Detect Concepts 1" />

                        </div>
                    </div>
                </div>
                <!--/ Abstract. -->

            </div>
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{wust2025bongard,
                title={Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?},
                author={W{\"u}st, Antonia and Tobiasch, Tim and Helff, Lukas and Ibs, Inga and Stammer, Wolfgang and Dhami, Devendra S and Rothkopf, Constantin A and Kersting, Kristian},
                journal={nternational Conference on Machine Learning (ICML)},
                year={2025}
      }
      </code></pre>
        </div>
    </section>

    <div id="modal" class="modal">
        <div class="modal-content">
            <span class="close">&times;</span>
            <p id="modal-message"></p>
            <canvas id="fireworks-canvas"></canvas>
        </div>
    </div>

    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="https://arxiv.org/pdf/2406.09949">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/ml-research/NeuralConceptBinder" class="external-link"
                    disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This work was supported by the Priority
                            Program (SPP) 2422 in the subproject “Optimization of
                            active surface design of high-speed progressive tools us-
                            ing machine and deep learning algorithms“ funded by
                            the German Research Foundation (DFG). We acknowl-
                            edge support of the hessian.AI Service Center (funded by
                            the Federal Ministry of Education and Research, BMBF,
                            grant No 01IS22091), the “Third Wave of AI”, and “The
                            Adaptive Mind”. The work was also supported by the
                            LOEWE research priority program “WhiteBox” [grant num-
                            ber LOEWE/ 2/13/519/03/06.001(0010)/77] (funded by the
                            Hessian Ministry of Higher Education, Research, Science
                            and the Arts). Further, this work was funded by the Euro-
                            pean Union (Grant Agreement no. 101120763 - TANGO).
                            Views and opinions expressed are however those of the
                            author(s) only and do not necessarily reflect those of the
                            European Union or the European Health and Digital Exec-
                            utive Agency (HaDEA). Neither the European Union nor
                            the granting authority can be held responsible for them.
                            The authors of the Eindhoven University of Technology re-
                            ceived support from their Department of Mathematics and
                            Computer Science and the Eindhoven Artificial Intelligence
                            Systems Institute.
                        </p>
                        <p>The website template is based on the source code of <a
                                href="https://github.com/nerfies/nerfies.github.io">this
                                website</a>. </p>
                        <p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>