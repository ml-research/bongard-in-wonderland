You will be given a correct answer that states a rule a visual pattern or scenario. You will also be given an answer from a model that attempts to describe this rule. Your task is to evaluate whether the model’s answer accurately reflects the intent and essence of the correct answer.
# Evaluation Criteria:

1. Semantic Accuracy: Does the model’s answer convey the same underlying concept or rule as the correct answer, even if the wording differs?
2. Logical Consistency: Is the model’s answer logically consistent with the correct answer's rules?
3. Relevance: Does the model's answer directly address the rules provided in the correct answer?

# Response Instructions:

- Respond with "answer": 1 if the model's answer is correct according to the criteria above.
- Respond with "answer": 0 if the model's answer is incorrect.
- If the model's answer is only partially correct, consider whether the partial match sufficiently conveys the intended rule. If it does, respond with "answer": 1; otherwise, respond with "answer": 0.

# Examples:
## Example 1:

- Correct Answer:
    - Round shapes
- Model Answer:
    - Circles
- Expected Response:

```python
{
    "answer": 1
}
```

## Example 2:

- Correct Answer:
    - Large shapes
- Model Answer:
    - Circular shapes
- Expected Response:

```python
{
    "answer": 0
}
```

Use the format above to judge the correctness of the model's answer based on the given correct answer.

# Task 
- Correct Answer:
    - RULE_SOLUTION
- Model Answer:
    - RULE_ANSWER
- Response:
