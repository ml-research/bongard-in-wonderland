# Bongard in Wonderland
This is the official repository of the article ["Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?"](https://arxiv.org/abs/2410.19546). 

## Getting started
To run the code you can either set up a conda environment and install `requirements.txt` (without open-source models) or build the docker container to launch the other models on your machine. 

## Usage
The experimental scripts can be found in `experiments/`. You can execute them from the command line, e.g.,
```bash
python experiments/zero_shot_bp.py --model "gpt-4o"
```
Make sure to include your API access keys in the respective folders of the model, e.g., `gpt-4o/open-ai-key`.

The results of the evaluations will be stored in `results/`. The evaluation scripts, including the llm-judge can be found in `experiments/evaluate`. You can run those from the command line as well, e.g.,
```bash
python experiments/zero_shot_bp.py --model "gpt-4o" --mode "zero_shot"
```

## Data
We use the dataset provided by Depeweg et. al [1] which contains the 100 original Bongard Problems in high resolution ([Link here](https://osf.io/95dks/)). 
For the perception-focussed evaluation we considered the single diagrams of the BPs which can be generated by `utils/crop_images.ipynb`.

[1] Depeweg, S., Rothkopf, C.A., JÃ¤kel, F. (2024). [Solving Bongard Problems with a Visual Language and Pragmatic Constraints](https://onlinelibrary.wiley.com/doi/10.1111/cogs.13432). Cognitive Science, 48(5), e13432.

## Citation
If you find the code of this repository helpful, consider citing us.
```
@inproceedings{wust2bongard,
  title={Bongard in Wonderland: Visual Puzzles that Still Make AI Go Mad?},
  author={W{\"u}st, Antonia and Tobiasch, Tim and Helff, Lukas and Ibs, Inga and Stammer, Wolfgang and Dhami, Devendra Singh and Rothkopf, Constantin A and Kersting, Kristian},
  journal={arXiv preprint arXiv:2410.19546},
  year={2025}
}
```
